\chapter{Gerelateerd Werk}
\label{cha:gerelateerdwerk}

Het IDP systeem is reeds beschreven in verscheidene papers die de motivatie, opbouw en werking gedetailleerd uitleggen. Aan de basis liggen vooral de werken van \citep{de2014predicate} en \citep{de2014separating}. Beide papers vormen een basis en een introductie voor iedereen die zich wenst te verdiepen in IDP. Ze beschrijven de onderdelen van FO(\textperiodcentered) en hoe deze kunnen gebruikt worden om de regels van een probleem uit te drukken en hoe deze regels tenslotte gebruikt kunnen worden om meerdere vormen van inferentie te doen. 
\par
In een poging om de kloof tussen IDP en imperatieve programmeertalen te dichten, stelt \citep{vennekens2015lowering} in zijn werk de ontwikkeling van een API voor. Deze API die geschreven is in python, maakt het mogelijk om IDP te gebruiken vanuit deze vertrouwde omgeving. Python is \'{e}\'{e}n van de meest gebruikte programmeertalen en de auteur hoopt daarmee zoveel mogelijk mensen aan te spreken. De API laat toe om regels te beschrijven met de syntax van python, waardoor een ontwikkelaar zich niet bekend met FO(\textperiodcentered) moet maken. Een gepaste achtergrond in declaratief programmeren is echter wel vereist.
\par
Conflict Explanation binnen het domein van interactieve configuratie is een breed concept, en de technieken van IDP of die uit \citep{amilhastre2002consistency} zijn niet de enigste de gepubliceerd zijn. In \citep{o2005generating} wordt het concept van \textit{corrective explanations} voorgesteld. Oplossingen tot nu toe werden altijd gezien als de minimale set van variabelen waarvoor de geselecteerde waarde uit het domein ongedaan gemaakt dient te worden, zodanig dat de resterende selectie terug uitgebreid kan worden tot een geldig model. Een corrective explanation is redelijk gelijkaardig, het is nog altijd een minimale set van variabelen, maar in plaats van enkel te zeggen dat de keuzes voor deze variabelen ongedaan moet worden gemaakt is er een waarde uit het domein gegeven van de variabelen waarvoor geldt dat ze deel uitmaakt van een geldige selectie. De paper stelt CORRECTIVEEXP voor, een systematisch algoritme voor het zoeken van \textit{minimal corrective explanations}. Een vergelijkende studie met reeds bestaande technieken op verscheidene grote problemen toont aan dat het algoritme zeer goede resultaten boekt in de zin dat het snel oplossingen kan vinden. Dit is uiteraard essentieel aangezien dat interactieve configuratie problemen een snelle reactietijd vereisen.

In het werk van \citet{o2007representative} wordt de term \textit{Representative Explanations} voorgesteld. De meeste aanpakken voor conflict explanation baseren zich op de notie van een minimale set van niet-satisfieebare constraints ook wel genoemd minimale conflict set. De output van de unsatstructere in IDP is bijvoorbeeld zo een minimale conflict set. De auteurs zijn er echter van overtuigd dat de gebruiker meer nodig heeft dan enkel deze minimale conflict sets om satisfieerbaarheid te herstellen. Hierbij verwijzen ze naar \citep{friedrich2004elimination} waarin aangetoond wordt dat dit deze vorm van explanations misleidend kunnen zijn. Ze verklaren enkel de oorzaak van het conflict, maar bieden geen oplossingen. Als alternatief wordt voorgesteld een explanation voor te stellen als een set van maximaal consistente subsets binnen de conflict sets, gepaard met hun minimaal inconsistente set. Zo definieert de schrijver de notie van representativiteit, zodat de set van berekende representative explanations representatief is voor alle maximaal consistente subsets en hun minimaal inconsistente subsets. De methode REPRESENTATIVEXPLAIN garandeert dat de set van representative explanations in het slechtste geval lineair is met betrekking tot het aantal keuzes van de gebruiker.

In \citep{freuder2001explanation} krijgen explanations (verklaringen) een heel andere betekenis. Elke stap van het selectieproces (keuze van de gebruiker) van een interactief configuratie probleem brengt bepaalde gevolgen met zich mee. Het selecteren van een bepaalde keuze kan ervoor zorgen dat bepaalde keuzes in de toekomst niet meer mogelijk worden, of misschien worden bepaalde keuzes verplicht. Deze gevolgen (propagaties) worden berekend en getoond aan de gebruiker, met de bedoeling dat deze informatie meer inzicht kan geven over het configuratieprobleem verder opgelost kan worden. De structuur van een verklaring in het werk van \citep{freuder2001explanation} is die van een boom, die de aanloop beschrijft voor de huidige situatie in het selectieproces. Als de gebruiker in een situatie terecht komt waar bepaald keuze niet meer mogelijk is, of er geen keuzes meer mogelijk zijn dan kan het systeem een \textit{extended explanation} genereren op basis van de gevolgen die berekend zijn in alle voorgaande stappen. Deze boomstructuur bevat alle keuzes uit de voorgaande stappen, samen met een verklaring of met de vermelding dat ze gekozen zijn door de gebruiker. Op deze manier krijgt de gebruiker een gedetailleerde verklaring die verklaart hoe alle voorheen gemaakte keuzes tot de huidige situatie hebben geleid.